import streamlit as st
from PIL import Image
import torch
from transformers import DetrImageProcessor, DetrForObjectDetection
import numpy as np
import cv2

# Load the Hugging Face model and processor locally
@st.cache(allow_output_mutation=True)
def load_model():
    processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")
    model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")
    return processor, model

processor, model = load_model()

st.title('Image Component Detector')

# Image upload widget
uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if st.button('Analyse Image'):
    if uploaded_file is not None:
        # Load and display the image
        image = Image.open(uploaded_file)
        st.image(image, caption='Uploaded Image.', use_column_width=True)
        st.write("Analyzing...")

        # Convert the image to numpy array
        img_array = np.array(image)

        # Preprocess the image and perform inference
        inputs = processor(images=image, return_tensors="pt")
        outputs = model(**inputs)

        # Process the outputs
        target_sizes = torch.tensor([img_array.shape[:2]])
        results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]

        # Extract component names (labels), scores, and bounding boxes
        labels = results["labels"].numpy()
        scores = results["scores"].detach().numpy()
        boxes = results["boxes"].detach().numpy()

        # Display results with bounding boxes and labels
        st.write("Components detected in the image:")
        annotated_image = np.array(image)

        detected_components = []

        for i, (label, score, box) in enumerate(zip(labels, scores, boxes)):
            if score > 0.5:
                detected_component = model.config.id2label[label]
                ymin, xmin, ymax, xmax = box
                xmin, xmax, ymin, ymax = int(xmin), int(xmax), int(ymin), int(ymax)

                # Draw bounding box
                cv2.rectangle(annotated_image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)

                # Label the object with a number
                cv2.putText(annotated_image, str(i+1), (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

                detected_components.append((detected_component, score))

        # Display the annotated image
        st.image(annotated_image, caption='Annotated Image.', use_column_width=True)

        # Display detected components with their names and confidence scores
        st.write("Detected Components:")
        for i, (component, score) in enumerate(detected_components):
            st.write(f"{i+1}. {component}: Confidence - {score:.2f}")
